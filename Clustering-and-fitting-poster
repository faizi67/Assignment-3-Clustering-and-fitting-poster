import numpy as np                                      
import pandas as pd 
get_ipython().system('pip install -q pycountry')
import pycountry                                        
import statsmodels.api as sm                 
from errors import err_ranges               
import seaborn as sns                                   
import matplotlib.pyplot as plt                         
from sklearn.preprocessing import StandardScaler          
from sklearn.cluster import KMeans                      
from scipy.optimize import curve_fit                  


# In[2]:





# In[50]:


def process_climate_data(file_path):
    # Read the data from the CSV file, skipping the metadata rows
    data = pd.read_csv(file_path, skiprows=4)

    # Remove unnecessary columns
    data = data.iloc[:, :-1]

    # Create a dataset indexed by Country and Indicator
    country_data = data.set_index(["Country Name", "Indicator Name"])
    country_data.drop(["Country Code", "Indicator Code"], axis=1, inplace=True)

    # Transpose the country_data to have countries as rows and indicators as columns
    country_data = country_data.transpose()
    
    return country_data,data


# In[51]:


country_data,data=process_climate_data("wb_data.csv")


# In[79]:


selected_indicators = [
'CO2 emissions from solid fuel consumption (kt)',
'Electric power consumption (kWh per capita)',
'Urban population',
'Electric power consumption (kWh per capita)'
]

# In[ ]:


# Filter the dataset for the required indicators
extracted_results = data[data["Indicator Name"].isin(selected_indicators)]
# Extracting data for only countries we are interested in
countries_ls = [country.name for country in list(pycountry.countries)]
extracted_resutls = extracted_results[extracted_results["Country Name"].isin(countries_ls)]


# In[80]:


# Filter the dataset for the required indicators
filtered_data = data[data["Indicator Name"].isin(selected_indicators)]

# Get the list of country names we are interested in
countries_of_interest = [country.name for country in list(pycountry.countries)]

# Extract data for only the countries of interest
extracted_data = filtered_data[filtered_data["Country Name"].isin(countries_of_interest)]

# Reset the index
extracted_data.reset_index(drop=True, inplace=True)


# In[83]:


#missing values imputation   
#data has lot of missing values so this is the best strategy to impute missing values
data = extracted_data.fillna(method='ffill').fillna(method='bfill')
grouped_data = data.pivot_table(index='Country Name', columns='Indicator Name', values='2020')


# In[ ]:


# Data Visualization


# In[66]:


electric_consumption=grouped_data['Electric power consumption (kWh per capita)'].sort_values(ascending=False)[0:10]


# In[70]:


plt.figure(figsize=(12,5))
sns.barplot(x=electric_consumption.index,y=electric_consumption.values)
plt.title('Top  Countries with Most Electric Consumption for 2020')
plt.show()


# In[101]:


plt.figure(figsize=(12,5))
sns.lineplot(grouped_data['Agricultural land (sq. km)'].sort_values(ascending=False)[0:30])
plt.title('Countries with Most Agricultural Land in SQ for 2020')
plt.xticks(rotation=90)
plt.show()


# In[102]:


plt.figure(figsize=(12,5))
sns.lineplot(grouped_data['Urban population'].sort_values(ascending=False)[0:30])
plt.title('Most Urban Populated Countries for 2020')
plt.xticks(rotation=90)
plt.show()


# In[99]:





# In[104]:


grouped_data['CO2 emissions from solid fuel consumption (kt)'].sort_values(ascending=False)[0:10].plot(kind='bar')
plt.title('CO2 emissions from solid fuel consumption (kt) by Top Countries for 2020')
plt.show()


# In[58]:


# data Normalization
std_scaler=StandardScaler()
scaled_data = std_scaler.fit_transform(grouped_data.values)
min=np.min(grouped_data.values)
max=np.max(grouped_data.values)


# In[108]:


# number of clusters
clusters = 3


# In[109]:


#KMeans Clustering
kmeans = KMeans(n_clusters=clusters, random_state=42)
cluster_out = kmeans.fit_predict(scaled_data)


# In[110]:


# Add the cluster labels to the dataset
grouped_data["Cluster"] = cluster_out
grouped_data.groupby("Cluster").mean()
labels = selected_indicators


# In[111]:


# Selecting one country from each cluster
grouped_data.groupby("Cluster").last()
# Comparing values for each country
grouped_data.groupby("Cluster").last().plot(kind="bar", figsize=(15, 5))
plt.title("Each Clusters")
plt.ylabel("Qty Measured")
plt.show()


# In[125]:


def forcast(x, a, b):
    return a*x + b

def f_model(x_values, y_values, linear_func, sigma=[1.0, 1.0]):
      popt, pcov = curve_fit(linear_func, x_values, y_values)
      x_pred = np.arange(2022, 2042)
      y_pred = linear_func(x_pred, *popt)
      lower, upper = err_ranges(x_pred, linear_func, popt, sigma)

    
    
      print("Predictions",y_pred)
      
      
      
      plt.figure(figsize=(12, 5))
      plt.plot(x_values, y_values, label='History Data',color='red')
      plt.plot(x_pred, y_pred, label='Future Predictions',color='black')
      plt.fill_between(x_pred, lower, upper, color='purple', alpha=0.2, label='CI')
      plt.legend()
      plt.title("PArable land (% of land area)")
      plt.xlabel('Year')
      plt.show()


# In[126]:


#getting required data to get train our model
values = country_data[("World", "Arable land (% of land area)")]
values=values.dropna()
X_input = values.index.astype("int")
y_input = values.values.astype("float64")

f_model(X_input, y_input, forcast)


# In[ ]:
